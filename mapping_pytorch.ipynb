{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "processed-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import wandb\n",
    "from omegaconf import OmegaConf as omg\n",
    "import torch\n",
    "import numpy as np\n",
    "from agent import Agent\n",
    "from trainer import Trainer, reward_fn\n",
    "from data_generator_v2 import DataGenerator, SimulatedAnnealing\n",
    "import time\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "norwegian-tucson",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_conf():\n",
    "    \"\"\"Quick method to load configuration (using OmegaConf). By default,\n",
    "    configuration is loaded from the default config file (config.yaml).\n",
    "    Another config file can be specific through command line.\n",
    "    Also, configuration can be over-written by command line.\n",
    "\n",
    "    Returns:\n",
    "        OmegaConf.DictConfig: OmegaConf object representing the configuration.\n",
    "    \"\"\"\n",
    "    default_conf = omg.create({\"config\" : \"config.yaml\"})\n",
    "\n",
    "    sys.argv = [a.strip(\"-\") for a in sys.argv]\n",
    "    cli_conf = omg.from_cli()\n",
    "\n",
    "    yaml_file = omg.merge(default_conf, cli_conf).config\n",
    "\n",
    "    yaml_conf = omg.load(yaml_file)\n",
    "\n",
    "    return omg.merge(default_conf, yaml_conf, cli_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "twelve-premises",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    conf = load_conf()\n",
    "    wandb.init(project=conf.proj_name, config=dict(conf))\n",
    "\n",
    "    agent = Agent(space_dim= conf.dimension, embed_hidden=conf.embed_hidden, enc_stacks=conf.enc_stacks, ff_hidden=conf.ff_hidden, enc_heads=conf.enc_heads, query_hidden=conf.query_hidden, att_hidden=conf.att_hidden, crit_hidden=conf.crit_hidden, n_history=conf.n_history, p_dropout=conf.p_dropout)\n",
    "    wandb.watch(agent)\n",
    "\n",
    "    dataset = DataGenerator()\n",
    "\n",
    "    trainer = Trainer(conf, agent, dataset)\n",
    "    trainer.run()\n",
    "\n",
    "    # Save trained agent\n",
    "    dir_ = str(conf.dimension)+'D_'+'MESH'+str(conf.max_len) +'_b'+str(conf.batch_size)+'_e'+str(conf.embed_hidden)+'_n'+str(conf.ff_hidden)+'_s'+str(conf.enc_stacks)+'_h'+str(conf.enc_heads)+ '_q'+str(conf.query_hidden) +'_a'+str(conf.att_hidden)+'_c'+str(conf.crit_hidden)+ '_lr'+str(conf.lr)+'_d'+str(conf.lr_decay_steps)+'_'+str(conf.lr_decay_rate)+ '_steps'+str(conf.steps)\n",
    "    path = \"save/\"+dir_\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    save_path= str(path)+'/'+str(conf.model_path)\n",
    "    torch.save(agent.state_dict(), save_path)\n",
    "\n",
    "    input_test = []\n",
    "    for _ in range (conf.batch_size): \n",
    "        input_test1 = np.loadtxt(\"mpeg_4x3.txt\", delimiter=\",\")\n",
    "        input_test.append(input_test1)\n",
    "\n",
    "    if conf.test:\n",
    "        device = torch.device(conf.device)\n",
    "        # Load trained agent\n",
    "        agent.load_state_dict(torch.load(save_path))\n",
    "        agent.eval()\n",
    "        agent = agent.to(device)\n",
    "        start_time = time.time()\n",
    "        running_reward = 0\n",
    "        for _ in range(conf.test_steps):\n",
    "            #input_batch = dataset.test_batch(conf.batch_size, conf.max_len, conf.dimension, shuffle=False)\n",
    "            input_batch = torch.Tensor(input_test).to(device)\n",
    "\n",
    "            tour, *_ = agent(input_batch)\n",
    "\n",
    "            reward = reward_fn(input_batch, tour, conf.x_dim, conf.batch_size)\n",
    "\n",
    "            # Find best solution\n",
    "            j = reward.argmin()\n",
    "            best_tour = tour[j][:].tolist()\n",
    "\n",
    "            # Log\n",
    "            running_reward += reward[j]\n",
    "\n",
    "            # Display\n",
    "            print('Reward (before 2 opt)', reward[j],'tour', best_tour)\n",
    "            opt_tour, opt_length = dataset.loop2opt(input_batch.cpu()[j], best_tour, conf.x_dim)\n",
    "            print('Reward (with 2 opt)', opt_length, 'opt_tour',opt_tour)\n",
    "            #dataset.visualize_2D_trip(opt_tour)\n",
    "\n",
    "        wandb.run.summary[\"test_reward\"] = running_reward / conf.test_steps\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wrapped-symphony",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: jagadheesh27 (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.10.29 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.20<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">giddy-smoke-151</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jagadheesh27/encode_attend_navigate\" target=\"_blank\">https://wandb.ai/jagadheesh27/encode_attend_navigate</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jagadheesh27/encode_attend_navigate/runs/29z51jd1\" target=\"_blank\">https://wandb.ai/jagadheesh27/encode_attend_navigate/runs/29z51jd1</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\Samala_Jagadheesh\\mapping_new\\wandb\\run-20210506_131101-29z51jd1</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward (before 2 opt) tensor(5893.) tour [6, 9, 4, 7, 2, 10, 8, 3, 11, 5, 1, 0]\n",
      "Reward (with 2 opt) [4456.] opt_tour [ 6  7  9  5 11  3  4  2 10  8  0  1]\n",
      "Reward (before 2 opt) tensor(5624.) tour [6, 11, 3, 0, 9, 7, 4, 2, 1, 8, 5, 10]\n",
      "Reward (with 2 opt) [4645.] opt_tour [ 6 11  3  0  7  9  4  8 10  5  2  1]\n",
      "Reward (before 2 opt) tensor(6137.) tour [6, 0, 5, 10, 8, 9, 4, 3, 11, 1, 7, 2]\n",
      "Reward (with 2 opt) [5251.] opt_tour [ 6 10  0  5  8  9  4  3 11  7  2  1]\n",
      "Reward (before 2 opt) tensor(6233.) tour [6, 9, 4, 11, 10, 3, 8, 0, 5, 2, 7, 1]\n",
      "Reward (with 2 opt) [4214.] opt_tour [ 6  9  4  8 11 10  3  2  7  1  0  5]\n",
      "Reward (before 2 opt) tensor(5110.) tour [6, 11, 7, 1, 9, 3, 10, 8, 0, 4, 5, 2]\n",
      "Reward (with 2 opt) [4025.] opt_tour [ 6 11  7  1  9  4  0  8 10  3  2  5]\n",
      "Reward (before 2 opt) tensor(5560.) tour [6, 9, 4, 0, 7, 2, 3, 11, 5, 10, 1, 8]\n",
      "Reward (with 2 opt) [4413.] opt_tour [ 6 11 10  5  7  9  4  3  8  1  0  2]\n",
      "Reward (before 2 opt) tensor(5452.) tour [6, 9, 2, 8, 3, 4, 0, 10, 7, 11, 5, 1]\n",
      "Reward (with 2 opt) [4635.] opt_tour [ 6  7 10  0  9  4  3  5 11  2  8  1]\n",
      "Reward (before 2 opt) tensor(6367.) tour [6, 4, 9, 7, 11, 8, 0, 3, 10, 2, 5, 1]\n",
      "Reward (with 2 opt) [4816.] opt_tour [ 6  0  9  8 11  7  4  3 10  1  2  5]\n",
      "Reward (before 2 opt) tensor(4275.) tour [6, 11, 10, 5, 9, 4, 3, 1, 7, 2, 0, 8]\n",
      "Reward (with 2 opt) [4025.] opt_tour [ 6 11 10  5  9  4  3  2  7  0  1  8]\n",
      "Reward (before 2 opt) tensor(5610.) tour [6, 11, 7, 5, 4, 9, 3, 1, 0, 10, 2, 8]\n",
      "Reward (with 2 opt) [4230.] opt_tour [ 6  9  4  3 11  1  0  5  7 10  2  8]\n",
      "--- 16.67831778526306 seconds ---\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "medieval-resort",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "dataset = DataGenerator()\n",
    "input_test = dataset.train_batch(10, 12, 12, 4, 3)\n",
    "input_batch  = torch.Tensor(input_test).to('cpu')\n",
    "m = nn.Conv1d(12, 128, 1, stride=1)\n",
    "n = nn.Linear(12, 128)\n",
    "input = torch.randn(20, 16, 50)\n",
    "output = m(input_batch)#.transpose(1, 2)\n",
    "output1 = n(input_batch).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "interested-residence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 128, 12])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "forced-liberia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward (before 2 opt) tensor(5253.5000) tour [1, 4, 0, 9, 8, 2, 11, 6, 5, 3, 10, 7]\n",
      "--- 0.6699981689453125 seconds ---\n",
      "Reward (with 2 opt) [4617.5] opt_tour [ 1  0  4  9  8  2 11  6  5 10  3  7]\n",
      "--- 1.134000301361084 seconds ---\n",
      "---total time 1.1349973678588867 seconds ---\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "    temp = 1000\n",
    "    stopping_temp = 0.00001\n",
    "    alpha = 0.995\n",
    "    stopping_iter = 10000\n",
    "    conf = load_conf()\n",
    "    dataset = DataGenerator()\n",
    "    agent = Agent(space_dim= conf.dimension, embed_hidden=conf.embed_hidden, enc_stacks=conf.enc_stacks, ff_hidden=conf.ff_hidden, enc_heads=conf.enc_heads, query_hidden=conf.query_hidden, att_hidden=conf.att_hidden, crit_hidden=conf.crit_hidden, n_history=conf.n_history, p_dropout=conf.p_dropout)\n",
    "    dir_ = str(conf.dimension)+'D_'+'MESH'+str(conf.max_len) +'_b'+str(conf.batch_size)+'_e'+str(conf.embed_hidden)+'_n'+str(conf.ff_hidden)+'_s'+str(conf.enc_stacks)+'_h'+str(conf.enc_heads)+ '_q'+str(conf.query_hidden) +'_a'+str(conf.att_hidden)+'_c'+str(conf.crit_hidden)+ '_lr'+str(conf.lr)+'_d'+str(conf.lr_decay_steps)+'_'+str(conf.lr_decay_rate)+ '_steps'+str(conf.steps)\n",
    "    path = \"save/\"+dir_\n",
    "    save_path= str(path)+'/'+str(conf.model_path)\n",
    "    #input_test = dataset.train_batch(conf.batch_size-1, conf.max_len, conf.dimension, conf.x_dim, conf.y_dim)\n",
    "    input_test = []\n",
    "    for _ in range (128):#conf.batch_size):        \n",
    "        A=np.zeros((conf.max_len,conf.max_len),dtype='float')\n",
    "        app = pd.read_csv('mpeg.csv')\n",
    "        for i in range ( len(app)):\n",
    "            A[app.source[i]][app.target[i]]= app.weight[i]\n",
    "        input_test.append(A)\n",
    "\n",
    "    if conf.test:\n",
    "        device = torch.device(conf.device)\n",
    "        # Load trained agent\n",
    "        agent.load_state_dict(torch.load(save_path))\n",
    "        agent.eval()\n",
    "        agent = agent.to(device)\n",
    "        start_time = time.time()\n",
    "        running_reward = 0\n",
    "        for _ in range(1):#conf.test_steps):\n",
    "            #input_batch = dataset.test_batch(conf.batch_size, conf.max_len, conf.dimension, shuffle=False)\n",
    "            input_batch = torch.Tensor(input_test).to(device)\n",
    "\n",
    "            tour, *_ = agent(input_batch)\n",
    "\n",
    "            reward = reward_fn(input_batch, tour, conf.x_dim, conf.batch_size)\n",
    "\n",
    "            # Find best solution\n",
    "            j = reward.argmin()\n",
    "            #j=127\n",
    "            best_tour = tour[j][:].tolist()\n",
    "\n",
    "            # Log\n",
    "            running_reward += reward[j]\n",
    "\n",
    "            # Display\n",
    "            print('Reward (before 2 opt)', reward[j],'tour', best_tour)\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "            opt_tour, opt_length = dataset.loop2opt(input_batch.cpu()[j], best_tour, conf.x_dim)\n",
    "            print('Reward (with 2 opt)', opt_length, 'opt_tour',opt_tour)\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "            #sa = SimulatedAnnealing(input_batch.cpu()[j], best_tour, conf.x_dim, temp, alpha, stopping_temp, stopping_iter)\n",
    "            #SA_length, SA_tour = sa.anneal()\n",
    "            #print('Reward (with SA)', SA_length, 'SA_tour',SA_tour)\n",
    "            #print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "            #dataset.visualize_2D_trip(opt_tour)\n",
    "        \n",
    "        print(\"---total time %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "blessed-demonstration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([31411.0000, 15861.0000, 25629.0000, 21178.0000, 22216.0000, 25314.0000,\n",
       "        35372.0000, 16938.0000, 19206.0000, 24354.0000, 17212.0000, 20431.0000,\n",
       "        18271.0000, 24972.0000, 19832.0000, 26592.0000, 21302.0000, 15859.0000,\n",
       "        19294.0000, 19172.0000, 15141.0000, 22694.0000, 17635.0000, 22763.0000,\n",
       "        25077.0000, 23137.0000, 22828.0000, 28864.0000, 12551.0000, 23071.0000,\n",
       "        20330.0000, 19898.0000, 22069.0000, 28870.0000, 27339.0000, 13757.0000,\n",
       "        18659.0000, 24120.0000, 16651.0000, 23384.0000, 21281.0000, 27780.0000,\n",
       "        30325.0000, 26272.0000, 24135.0000, 23200.0000, 24802.0000, 29562.0000,\n",
       "        27182.0000, 25323.0000, 19153.0000, 24146.0000, 21987.0000, 30765.0000,\n",
       "        33482.0000, 27550.0000, 23741.0000, 24274.0000, 20677.0000, 25385.0000,\n",
       "        25685.0000, 21290.0000, 22664.0000, 29846.0000, 18533.0000, 16804.0000,\n",
       "        25279.0000, 19076.0000, 19567.0000, 16952.0000, 20323.0000, 18554.0000,\n",
       "        18659.0000, 22474.0000, 20081.0000, 31240.0000, 29142.0000, 12789.0000,\n",
       "        18205.0000, 31301.0000, 19272.0000, 30279.0000, 22191.0000, 23358.0000,\n",
       "        14272.0000, 21784.0000, 22043.0000, 20397.0000, 21435.0000, 30828.0000,\n",
       "        21324.0000, 21538.0000, 16345.0000, 17747.0000, 28432.0000, 22783.0000,\n",
       "        17956.0000, 17493.0000, 32063.0000, 22992.0000, 25133.0000, 27425.0000,\n",
       "        27475.0000, 28812.0000, 12986.0000, 24164.0000, 28371.0000, 24491.0000,\n",
       "        28629.0000, 15589.0000, 23865.0000, 21311.0000, 19386.0000, 19537.0000,\n",
       "        28366.0000, 33180.0000, 20426.0000, 24439.0000, 26954.0000, 22849.0000,\n",
       "        33136.0000, 30835.0000, 19329.0000, 15451.0000, 27377.0000, 18720.0000,\n",
       "         8809.5000,  7715.5000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "growing-calvin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12D_MESH12_b128_e128_n512_s3_h16_q360_a256_c256_lr0.001_d5000_0.96_steps30000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'save/12D_MESH12_b128_e128_n512_s3_h16_q360_a256_c256_lr0.001_d5000_0.96_steps30000\\\\config.yaml'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = load_conf()\n",
    "dir_ = str(conf.dimension)+'D_'+'MESH'+str(conf.max_len) +'_b'+str(conf.batch_size)+'_e'+str(conf.embed_hidden)+'_n'+str(conf.ff_hidden)+'_s'+str(conf.enc_stacks)+'_h'+str(conf.enc_heads)+ '_q'+str(conf.query_hidden) +'_a'+str(conf.att_hidden)+'_c'+str(conf.crit_hidden)+ '_lr'+str(conf.lr)+'_d'+str(conf.lr_decay_steps)+'_'+str(conf.lr_decay_rate)+ '_steps'+str(conf.steps)\n",
    "print(dir_)\n",
    "path = \"save/\"+dir_\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "#save_path= str(path)+'/'+str(conf.model_path)\n",
    "#print (path)\n",
    "from shutil import copy\n",
    "copy('config.yaml',path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "trying-transition",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-c1914db31e2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mapp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mwd.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5134\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5135\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5136\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5138\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "A=np.zeros((12,12),dtype='float')\n",
    "app = pd.read_csv('mwd.csv')\n",
    "for i in range ( len(app)):\n",
    "    A[app.source[i]][app.target[i]]= app.weight[i]\n",
    "    A[app.target[i]][app.source[i]]= app.weight[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "breathing-mineral",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "        import random\n",
    "        import networkx as nx\n",
    "        input_batch = []\n",
    "        \n",
    "\n",
    "        size1 = 12 #mesh size 4x3\n",
    "        for _ in range(1):        \n",
    "            size = random.randint((size1 - 4),size1)\n",
    "\n",
    "            G=nx.connected_watts_strogatz_graph(size, 5, 0.5, tries=100, seed=None)\n",
    "            for (u, v) in G.edges():\n",
    "                G.edges[u,v]['weight'] = random.randint(1,1000)\n",
    "            #C=G.to_undirected()\n",
    "            #B=nx.to_numpy_array(C)\n",
    "            app= nx.to_pandas_edgelist(G)\n",
    "            A=np.zeros((size1,size1),dtype='float')\n",
    "            for i in range (len(app)):\n",
    "                A[app.source[i]][app.target[i]]= app.weight[i]\n",
    "            #A[:B.shape[0], :B.shape[1]] = B\n",
    "            #A=A.flatten()\n",
    "            input_batch.append(A)\n",
    "            gg=nx.from_numpy_array(A)\n",
    "            app1 = nx.to_pandas_edgelist(gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "available-agriculture",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataGenerator()\n",
    "input_test = dataset.train_batch(10, 12, 12, 4, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "optional-junior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00e+00 0.00e+00 0.00e+00 0.00e+00 1.90e+02 0.00e+00 0.00e+00 0.00e+00\n",
      "  0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n",
      " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 5.00e-01 0.00e+00 0.00e+00 0.00e+00\n",
      "  0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n",
      " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 6.00e+01 4.00e+01 0.00e+00 0.00e+00\n",
      "  0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n",
      " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 6.00e+02 4.00e+01 0.00e+00 0.00e+00\n",
      "  0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n",
      " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
      "  5.00e-01 9.10e+02 3.20e+01 0.00e+00]\n",
      " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
      "  0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n",
      " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 2.50e+02\n",
      "  0.00e+00 6.70e+02 1.73e+02 5.00e+02]\n",
      " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
      "  0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n",
      " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
      "  0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n",
      " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
      "  0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n",
      " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
      "  0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n",
      " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
      "  0.00e+00 0.00e+00 0.00e+00 0.00e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(input_test[9])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
